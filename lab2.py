#!/usr/bin/python3
"""
IS Lab 2
Dylan Bannon <drb2857@rit.edu>

This program has three parts:
1. Feature extraction
   Takes a number of audio files (wave format), divides them into 1 second clips and extracts the MFCC feature from
   each clip. The results are saved in a JSON file in the project root called 'extracted_features.json'
2. Model generation
   Builds and trains a decision tree based on the examples generated by the feature extraction. The generated model
   is saved in a binary file called 'decision_tree.model'
3. Prediction
   Takes in an audio file and runs it through the model generated by the model generation. Model must be called
   'decision_tree.model' and be located in the same directory as lab2.py. The output is the predicted language (English,
    Spanish, or Polish).
"""

from python_speech_features import mfcc
from enum import Enum
import scipy.io.wavfile as wav
import sys
import glob
import time
import json
import math
import pickle


FEATURES_JSON_FILENAME = 'extracted_features.json'
MODEL_FILENAME = 'decision_tree.model'
NUM_FEATURES = 13


def main(args):
    if args[0] == "extract_features":
        extract_mfcc()
    elif args[0] == "generate_model":
        generate_model()
    else:
        assert len(args) == 2, "Must specify filename for language prediction"
        prediction = predict_language(args[1])
        print("Predicted language: {}".format(prediction))


def extract_mfcc():
    """
    Extracts the MFCC feature from each one second interval of each file in the audio_data folder (training data)
    Saves results in a JSON file called 'extracted_features.json'. The format is as follows:
    {
        language1:
        [
            [example_list1],
            [example_list2],
            ...
        ],
        language2:
        [
            [example_list1],
            [example_list2],
            ...
        ],
        ...
    }
    """
    print("Extracting features from audio files in audio_data folder...", end=' ', flush=True)
    start_time = time.time()
    json_dict = {Language.English.name: [], Language.Spanish.name: [], Language.Polish.name: []}

    for filename in glob.iglob('audio_data/*.wav'):
        # determine language from filename
        filename_parts = filename.split('.')
        filename_path = filename_parts[0].split('/')
        if filename_path[1].startswith('en'):
            language = Language.English
        elif filename_path[1].startswith('es'):
            language = Language.Spanish
        else:
            language = Language.Polish

        # digest the file, put the resulting examples in the json dict
        examples = digest_audio_file(filename)
        json_dict[language.name].extend(examples)

    # dump that crap into a JSON file!
    with open(FEATURES_JSON_FILENAME, 'w') as outfile:
        json.dump(json_dict, outfile)

    end_time = time.time()
    print("Done.")
    print("Extracted features in {0:.2f} seconds. Results in 'extracted_features.json'.".format(end_time - start_time))


def generate_model():
    """
    Generates a decision tree from the features present in ./extracted_features.json. Model is saved in
    ./decision_tree.model
    """
    with open(FEATURES_JSON_FILENAME, 'r') as examples_file:
        examples_dict = json.load(examples_file)
    flat_data = []
    for language in examples_dict.keys():
        for row in examples_dict[language]:
            row.append(language)
            flat_data.append(row)

    tree = build_tree(flat_data)
    with open(MODEL_FILENAME, 'wb') as out_file:
        pickle.dump(tree, out_file, pickle.HIGHEST_PROTOCOL)


def divide_data(rows, feature_num, value):
    """
    Splits the given data into two sets based on the given feature number and value
    :param rows: data to split
    :param feature_num: feature to compare against
    :param value: value to compare to
    :return: set1, containing all rows where the specified feature >= the value and set2, containing all other rows
    """
    split_function = lambda row: row[feature_num] >= value
    set1 = [row for row in rows if split_function(row)]
    set2 = [row for row in rows if not split_function(row)]
    return set1, set2


def unique_results(data):
    """
    Calculates the number of unique results per class in the training data
    :param data:
    :return: a dictionary containing the results per class
    """
    results = {Language.English.name: 0, Language.Spanish.name: 0, Language.Polish.name: 0}
    for row in data:
        language = row[-1]
        results[language] += 1
    return results


def entropy(data):
    """
    Calculates the entropy of the given data
    :param data: list of examples
    :return: entropy of the data
    """
    # if the data is empty just return 0
    if len(data) == 0:
        return 0
    results = unique_results(data)
    ent = 0.0
    for language in results.keys():
        p = results[language] / len(data)
        # also return 0 if there are no results for the class
        if p == 0:
            return 0
        ent -= p * math.log2(p)
    return ent


def build_tree(data):
    """
    Recursively builds the decision tree based on information gain
    :param data: training data
    :return: the root of the decision tree
    """
    if len(data) == 0:
        return DecisionTreeNode()
    cur_score = entropy(data)

    best_info_gain = 0.0
    best_feature = None
    best_sets = None

    for feature_num in range(NUM_FEATURES):
        feature_values = []
        for row in data:
            feature_values.append(row[feature_num])
        for value in feature_values:
            # divide the data for each value
            set1, set2 = divide_data(data, feature_num, value)
            # calculate information gain
            p = len(set1) / len(data)
            info_gain = cur_score - p * entropy(set1) - (1 - p) * entropy(set2)
            if info_gain > best_info_gain and len(set1) > 0 and len(set2) > 0:
                # save feature and corresponding value with best info gain
                best_info_gain = info_gain
                best_feature = (feature_num, value)
                best_sets = (set1, set2)

        # recursively build the tree as long as we're still learning things
        if best_info_gain > 0:
            next_true = build_tree(best_sets[0])
            next_false = build_tree(best_sets[1])
            return DecisionTreeNode(feature_num=best_feature[0], value=best_feature[1],
                                    next_true=next_true, next_false=next_false)
        # no longer gaining anything useful, time for a leaf node
        else:
            return DecisionTreeNode(results=unique_results(data))


def predict_language(in_filename):
    """
    Runs the given audio file through the model specified by ./decision_tree.model, prints the predicted language (English,
    Spanish, or Polish).
    :param in_filename: filename of audio file to predict
    :return: the prediction
    """
    print("Loading tree from file...", end='', flush=True)
    with open(MODEL_FILENAME, 'rb') as tree_in_file:
        decision_tree = pickle.load(tree_in_file)
    print("Done")
    print("Predicting language of {}...".format(in_filename))
    examples = digest_audio_file(in_filename)
    votes = {Language.English.name: 0, Language.Spanish.name: 0, Language.Polish.name: 0}
    for example in examples:
        results = classify(example, decision_tree)
        for result in results:
            votes[result] = results[result]

    # prediction is the max of all of the votes
    prediction = max(votes, key=votes.get)
    return prediction


def classify(novel_data, tree):
    """
    Traverse the decision tree, asking questions until you reach a leaf node. Then return the results from that leaf
    which is a dictionary from the class to the number of votes for that class
    :param novel_data: new data to classify
    :param tree: a decision tree node
    :return: the results of the classification. Dictionary mapping class -> num_votes
    """
    if tree.results is not None:
        return tree.results

    value = novel_data[tree.feature_num]
    if value >= tree.value:
        branch = tree.next_true
    else:
        branch = tree.next_false
    return classify(novel_data, branch)


def digest_audio_file(filename):
    """
    Takes an incoming audio file, splits it into 1 second segments, calculates the MFCC of the segments, and returns
    a list of examples (each example is a list of length 13)
    :param filename: filename of the audio file
    :return: list of examples for the audio file
    """
    sample_rate, data = wav.read(filename)

    # split files into separate 1 second clips
    examples = []

    for i in range(0, len(data), sample_rate):
        new_data = data[i:i + sample_rate]
        mfcc_feat = mfcc(new_data, samplerate=sample_rate)

        # this speech library automatically splits the source into 5 ms segments but that is too granular for my
        # purposes, here I am averaging all of the values per feature and putting the result in an array for later
        feature_list = [0] * NUM_FEATURES
        for j in range(NUM_FEATURES):
            for k in range(len(mfcc_feat)):
                feature_list[j] += mfcc_feat[k][j]
        feature_list = [j / len(mfcc_feat) for j in feature_list]

        examples.append(feature_list)
    return examples


class Language(Enum):
    """
    Enum for the language classes
    """
    English = 1
    Spanish = 2
    Polish = 3


class DecisionTreeNode:
    """
    A node of the decision tree
    """
    def __init__(self, feature_num=-1, value=-1, results=None, next_true=None, next_false=None):
        self.feature_num = feature_num
        self.value = value
        self.results = results
        self.next_true = next_true
        self.next_false = next_false


if __name__ == "__main__":
    assert len(sys.argv) >= 2, "Usage: python3 lab2.py " \
                               "[extract_features | generate_model | predict_language <filename>]"
    main(sys.argv[1:])
